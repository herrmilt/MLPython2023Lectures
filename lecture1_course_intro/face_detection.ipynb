{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fc3fd91",
   "metadata": {},
   "source": [
    "# Face Detection\n",
    "\n",
    "Face detection is a computer vision technique used to locate and identify human faces within images or video frames. It plays a crucial role in various applications, such as facial recognition, emotion detection, face tracking, and more.\n",
    "\n",
    "To train a face detector, lets collect a database with images and proper annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe078b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import os\n",
    "import pathlib\n",
    "import PIL\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D, Dense,Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66dd74",
   "metadata": {},
   "source": [
    "Remember, initialize the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d88017",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print('GPU', tf.test.gpu_device_name(), 'configured')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46837b59",
   "metadata": {},
   "source": [
    "Images stored in a folder, together with a CSV file with annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10109a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = \"data/faces/images\"\n",
    "dataset_path = \"data/faces/faces.csv\"\n",
    "\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd2d6d",
   "metadata": {},
   "source": [
    "If many faces in the same file, each face appears in a different row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955f3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['image_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a654388e",
   "metadata": {},
   "source": [
    "Lets show the image with more faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6943693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=os.path.join(images_path, \"00000657.jpg\"), width=400, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae480ba",
   "metadata": {},
   "source": [
    "Lets show images with annotated faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c3f6b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Specify the image name for which you want to draw rectangles\n",
    "target_image_name = '00003172.jpg'\n",
    "\n",
    "# Filter the DataFrame to get the relevant rows for the target image\n",
    "target_df = dataset[dataset['image_name'] == target_image_name]\n",
    "\n",
    "# Load and display the target image\n",
    "image_path = os.path.join(images_path, target_image_name)  # Adjust the path to your image directory\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "image = plt.imread(image_path)\n",
    "ax.imshow(image)\n",
    "\n",
    "\n",
    "# Iterate over the rows of the target DataFrame and draw rectangles\n",
    "for index, row in target_df.iterrows():\n",
    "    x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "    width = x1 - x0\n",
    "    height = y1 - y0\n",
    "    rect = patches.Rectangle((x0, y0), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c42cf0",
   "metadata": {},
   "source": [
    "**Note**. Like in many resources available in internet, there are errors in the annotations!\n",
    "- This will significantly degrades the quality of any model obtained using is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f8ef3",
   "metadata": {},
   "source": [
    "Lest put all the annotations of every image together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c3eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for i in dataset[\"image_name\"]:\n",
    "    if i not in data:\n",
    "        data[i] = []\n",
    "for index, img_name in enumerate(dataset[\"image_name\"]):\n",
    "    width = dataset[\"width\"][index]\n",
    "    height = dataset[\"height\"][index]\n",
    "    x0 = dataset[\"x0\"][index]\n",
    "    x1 = dataset[\"x1\"][index]\n",
    "    y0 = dataset[\"y0\"][index]\n",
    "    y1 = dataset[\"y1\"][index]\n",
    "    \n",
    "    new_x0 = int((x0/width)*224)\n",
    "    new_x1 = int((x1/width)*224)\n",
    "    new_y0 = int((y0/width)*224)\n",
    "    new_y1 = int((y1/width)*224)\n",
    "    \n",
    "    data[img_name].append(new_x0)\n",
    "    data[img_name].append(new_x1)\n",
    "    data[img_name].append(new_y0)\n",
    "    data[img_name].append(new_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb18faf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data['00001736.jpg'])\n",
    "print(data['00002997.jpg'])\n",
    "print(data['00003121.jpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fad3df",
   "metadata": {},
   "source": [
    "Read all the images, resizing them to 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b9206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = os.listdir(images_path)\n",
    "images = []\n",
    "for img_name in data.keys():\n",
    "    for itr in img_dir:\n",
    "        if img_name == itr:\n",
    "            img_arr = cv.imread(os.path.join(images_path, img_name),\n",
    "                               cv.IMREAD_GRAYSCALE)\n",
    "            img_resize = cv.resize(img_arr, (224, 224))\n",
    "            images.append(img_resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfae2e1",
   "metadata": {},
   "source": [
    "Convert images to a numpy array and add a new dimension (will be clear in the CNN lecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "images = np.expand_dims(images, axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b4d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of images : {images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec93d09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(images[i], cmap = 'gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb954d",
   "metadata": {},
   "source": [
    "## Creating BBoxes (or Bounding Boxes) for Object Detection\n",
    "\n",
    "We transform the bounding boxes to be used to train the network. \n",
    "- The network uses a fixed number of output values (one per output neuron).\n",
    "- There are figures with different number of boxes\n",
    "- Solution: Transform all using the largest number of boxes. If some figure has less boxes, zeros are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abac889",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = []\n",
    "for box in data.keys():\n",
    "    bbox.append(data[box])\n",
    "\n",
    "max_bbox = 0\n",
    "for i in range(len(bbox)):\n",
    "    max_bbox = max(max_bbox, len(bbox[i]))\n",
    "\n",
    "for i in range(len(bbox)):\n",
    "    if int(max_bbox) - len(bbox[i]) != 0:\n",
    "        for j in range(int(max_bbox) - len(bbox[i])):\n",
    "            bbox[i].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a758e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = np.array(bbox)\n",
    "print(bbox[0])\n",
    "print(bbox[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41095f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c404fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets normalize\n",
    "images = images/255\n",
    "bbox = bbox/224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e9faa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, bbox, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92fef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a CNN Sequential Model\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, 3, input_shape = (224,224,1), padding = \"same\", activation = \"relu\"),\n",
    "    MaxPool2D(pool_size = 2),\n",
    "    Conv2D(64, 3, padding = \"same\", activation = \"relu\"),\n",
    "    MaxPool2D(pool_size = 2),\n",
    "    Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n",
    "    MaxPool2D(pool_size = 2),\n",
    "    Conv2D(256, 3, padding = \"same\", activation = \"relu\"),\n",
    "    MaxPool2D(pool_size = 2),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(48, activation = 'sigmoid') #output layer has 48 neurons to match the bbox dimensions\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc1d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4343cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', \n",
    "              optimizer = tf.keras.optimizers.Adam(), \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de92c644",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data = (X_test, y_test), epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd385f5",
   "metadata": {},
   "source": [
    "Plotting code adapted from Daniel Bourke's Course on TensorFlow and Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ccbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "    '''\n",
    "    Returns separate loss curves for training and validation metrics\n",
    "    '''\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    epochs = range(len(history.history['loss'])) #generates the sequence of indices in a list, in this case epochs\n",
    "\n",
    "    #Plot loss\n",
    "    plt.plot(epochs, loss, label = 'training loss')\n",
    "    plt.plot(epochs, val_loss, label = 'val_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    #Plot accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, accuracy, label = 'training accuracy')\n",
    "    plt.plot(epochs, val_accuracy, label = 'val_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    \n",
    "plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5810999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d92249",
   "metadata": {},
   "source": [
    "## Model 2: Adding a BatchNormalisation and Dropout Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de29008",
   "metadata": {},
   "source": [
    "If you want to improve the results, you can do some modifications in the network layers or the parameters, or both.\n",
    "- In this case, we add BatchNormalization and Dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e49ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential([\n",
    "    Conv2D(32, 3, input_shape = (224,224,1), activation = 'relu'),\n",
    "    Dropout(0.1),\n",
    "    MaxPool2D(pool_size = 2),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, 3, activation = 'relu'),\n",
    "    Dropout(0.2),\n",
    "    MaxPool2D(pool_size = 2),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, 3, activation = 'relu'),\n",
    "    Dropout(0.3),\n",
    "    MaxPool2D(pool_size = 2),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(256, 3, activation = 'relu'),\n",
    "    Dropout(0.4),\n",
    "    MaxPool2D(pool_size = 2),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dense(48, activation = 'sigmoid') #output layer\n",
    "])\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bec3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss = 'binary_crossentropy',\n",
    "               optimizer= tf.keras.optimizers.Adam(),\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c58dc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_2 = model_2.fit(X_train, y_train, validation_data = (X_test, y_test),\n",
    "           batch_size = 8, epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9dd5f3",
   "metadata": {},
   "source": [
    "Slight improvement in the accuracy over the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe56af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8704c",
   "metadata": {},
   "source": [
    "Lets evaluate the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d63f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.evaluate(X_test, y_test, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833a408f",
   "metadata": {},
   "source": [
    "Now, lets see some detections on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model,idx):\n",
    "    '''\n",
    "    Plots the decision boundary for a model on an image specified by its index.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    model: The model whose predictions we are testing\n",
    "    idx: The index of the image as it appears in the dataset\n",
    "    '''\n",
    "    model_prediction = model.predict(X_test[idx].reshape(1, 224, 224, 1))\n",
    "    model_prediction = model_prediction[0]\n",
    "    img = X_test[idx]\n",
    "    count = 0\n",
    "    bbox1 = []\n",
    "    for i in model_prediction:\n",
    "        bbox1.append(i)\n",
    "        count+=1\n",
    "        if count == 4:\n",
    "            count = 0\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(img)\n",
    "            x1 = int(bbox1[0]*224)\n",
    "            y1 = int(bbox1[1]*224)\n",
    "            x2 = int(bbox1[2]*224)\n",
    "            y2 = int(bbox1[3]*224)\n",
    "            plt.gca().add_patch(matplotlib.patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth = 1,\n",
    "                                                 edgecolor = 'r', facecolor = \"none\"))\n",
    "            bbox1 = []\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6004906d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_predictions(model,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5332a0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_predictions(model_2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba9849",
   "metadata": {},
   "source": [
    "**Note**. This is only a demo for teaching purposes. For real face detection we need to use a different kind of neural network (Convolutional NN) and much more complex network architectures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_lectures",
   "language": "python",
   "name": "python_lectures"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
