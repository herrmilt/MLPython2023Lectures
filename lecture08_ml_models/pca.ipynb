{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb26df14",
   "metadata": {},
   "source": [
    "# Principal Components Analysis\n",
    "Principal Component Analysis (PCA) is a dimensionality reduction technique commonly used in machine learning and data analysis. \n",
    "- It aims to transform a high-dimensional dataset into a lower-dimensional representation while retaining most of the relevant information.\n",
    "\n",
    "Supose we have a collections of students and its grades in the English course. Grades from 0 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "grades = pd.DataFrame({\"english\": [8.0, 7.1, 10.0, 3.8, 1.4, 2.3]})\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832f0a66",
   "metadata": {},
   "source": [
    "Lets represent this values in a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577272b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_, ax = plt.subplots(figsize=(3,3))\n",
    "ax.scatter(grades.english, np.full(len(grades), 2), c=[*'rrrbbb'])\n",
    "plt.xlabel('english')\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42630e6",
   "metadata": {},
   "source": [
    "It is evident that there are two distinct groups of students. The distances between students 1, 2, and 3 are more similar to each other compared to students 4, 5, and 6.\n",
    "\n",
    "Lets add now a second course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675cc9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades['math'] = [7, 6.5, 6.1, 4, 3.7, 2]\n",
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d24161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(3,3))\n",
    "ax.scatter(grades.english, grades.math, c=[*'rrrbbb'])\n",
    "plt.xlabel('english')\n",
    "plt.ylabel('math')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6648411c",
   "metadata": {},
   "source": [
    "We can observe that the objects remain clustered together when considering the two dimensions. Specifically, objects 1, 2, and 3 exhibit a high degree of similarity among themselves, while objects 4, 5, and 6 also demonstrate strong similarity within their group.\n",
    "\n",
    "Now, lets add a third course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades['history'] = [10, 9.2, 8.7, 6.4, 6.0, 5.8]\n",
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf75d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the data points in 3D\n",
    "ax.scatter(grades.english, grades.math, grades.history, c=[*'rrrbbb'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4c273",
   "metadata": {},
   "source": [
    "As you can see, the same objects keep clustered together.\n",
    "\n",
    "Lets add a new course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980afc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades['chemistry'] = [9.3, 8.4, 7.9, 4.3, 4.2, 3.9]\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37a6c3e",
   "metadata": {},
   "source": [
    "**Now we are no longer able to represent data in a plot, because we cannot see a 4D space.**\n",
    "\n",
    "Principal Components Analysis, or PCA, allows to represent a dataset with many dimensions into a new dataset with reduced number of dimensions, but keeping the most important information.\n",
    "- The principal components represent new orthogonal axes that capture the maximum variance in the data.\n",
    "- The main principal component is the line which, when all points are projected over it, their spread is the largest.\n",
    "\n",
    "In this example, it allows to represent the 4D information of grades into a 1D representation, which we can plot and understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d217a36",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=1)  # Select the number of components you want to keep\n",
    "principal_components = pca.fit_transform(grades)\n",
    "\n",
    "# Create a new DataFrame with the principal components\n",
    "principal_df = pd.DataFrame(principal_components, columns=['PC1'])\n",
    "\n",
    "# Plot the data in a 2D scatter plot\n",
    "plt.scatter(principal_df['PC1'], np.full(len(grades), 2), c=[*'rrrbbb'])\n",
    "plt.xlabel('PC1')\n",
    "plt.yticks([])\n",
    "plt.title('PCA Scatter Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62cb592",
   "metadata": {},
   "source": [
    "Lets see the explained variance of the principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b4232c",
   "metadata": {},
   "source": [
    "The variance of all the original features is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25133d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grades.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa3bec",
   "metadata": {},
   "source": [
    "With a total of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2a130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.var().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a40a645",
   "metadata": {},
   "source": [
    "So, the explained variance ratio is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e7639",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b5dfb",
   "metadata": {},
   "source": [
    "Lets try now with two principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee567c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=2)  # Select the number of components you want to keep\n",
    "principal_components = pca.fit_transform(grades)\n",
    "\n",
    "# Create a new DataFrame with the principal components\n",
    "principal_df = pd.DataFrame(principal_components, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Plot the data in a 2D scatter plot\n",
    "plt.scatter(principal_df['PC1'], principal_df['PC2'], c=[*'rrrbbb'])\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('PCA Scatter Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad7c65",
   "metadata": {},
   "source": [
    "Lets see now the explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef27302",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d4ec6",
   "metadata": {},
   "source": [
    "Lets try with 3 PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70abf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=3)  # Select the number of components you want to keep\n",
    "principal_components = pca.fit_transform(grades)\n",
    "\n",
    "# Create a new DataFrame with the principal components\n",
    "principal_df = pd.DataFrame(principal_components, columns=['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9be1de",
   "metadata": {},
   "source": [
    "For showing PCA in a real live example, we will use the digit image dataset that we used before. Now we represent each image as a continuous collection of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deeb9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd983a5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Calculate the number of rows and columns for the grid\n",
    "n_rows = 4\n",
    "n_cols = 4\n",
    "\n",
    "# Create a new figure with the desired grid size\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5, 5))\n",
    "\n",
    "# Iterate over the image files and display them in the grid\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(x_train[i], cmap=\"gray\")\n",
    "    ax.set_title(f\"Number:{y_train[i]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "# Adjust the spacing and layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c602a23",
   "metadata": {},
   "source": [
    "Lets transfor the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca982286",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(x_train.reshape((-1, 28*28)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056b7860",
   "metadata": {},
   "source": [
    "We are unable to represent this information in a plot because it contains too much dimensions. Lets find the two most important PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce238158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=2) \n",
    "principal_components = pca.fit_transform(data)\n",
    "\n",
    "# Create a new DataFrame with the principal components\n",
    "principal_df = pd.DataFrame(principal_components, columns=['PC1', 'PC2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f140f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_variance = data.var().sum()\n",
    "print(\"Total variance\", total_variance)\n",
    "print(\"Explained variance per PC:\", pca.explained_variance_)\n",
    "print(\"- relative:\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15146d5",
   "metadata": {},
   "source": [
    "Remember, there are 784 features!!!\n",
    "\n",
    "Now, lets plot the PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1987dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(principal_df['PC1'], principal_df['PC2'], c=y_train, cmap=\"jet\")\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('PCA Scatter Plot')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22a66be",
   "metadata": {},
   "source": [
    "Lets filter some classes in order to analyze the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0723f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "together = principal_df.copy()\n",
    "together['digit'] = y_train\n",
    "\n",
    "def plot_digits(digits):\n",
    "    to_show = together[together.digit.isin(digits)]\n",
    "    plt.scatter(to_show.PC1, to_show.PC2, c=to_show.digit, cmap=\"jet\")\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.title('PCA Scatter Plot')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721fde24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits({0, 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9ae8e9",
   "metadata": {},
   "source": [
    "- It separates quite well 0 and 1\n",
    "- It is more variety in the 0 than in the ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b92373",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_digits({1, 7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf95290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits({6, 8})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d841f200",
   "metadata": {},
   "source": [
    "Not quite well separated.\n",
    "\n",
    "If we add more than three components, we can get a more accurate representation, but we can no longer visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=10)  \n",
    "principal_components = pca.fit_transform(data)\n",
    "\n",
    "# Create a new DataFrame with the principal components\n",
    "principal_df = pd.DataFrame(principal_components, columns=[f'PC{n}' for n in range(1, 11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecccf79b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_variance = data.var().sum()\n",
    "print(\"Total variance\", total_variance)\n",
    "print(\"Explained variance per PC:\", pca.explained_variance_)\n",
    "relative_var = pca.explained_variance_ratio_\n",
    "print(\"- relative:\", relative_var)\n",
    "print(\"- cumulative\", np.cumsum(relative_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825b98ee",
   "metadata": {},
   "source": [
    "So, taking only 10 principal components, I am able to explain almost half of the total variance of the original database with 784 features.\n",
    "\n",
    "Sumarizing:\n",
    "- PCA allows to transform datasets from higher dimensions to lower dimensions, keeping the most important information (related to variance)\n",
    "- It is a powerfull tool for visualization (and for other methods too!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_lectures]",
   "language": "python",
   "name": "conda-env-python_lectures-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
