{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c262c56a",
   "metadata": {},
   "source": [
    "# Basic terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9984fa6d",
   "metadata": {},
   "source": [
    "Supose I want to know the weight of a person based on its height. Since I know machine learning, I want to build a model based on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2c854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = [130, 150, 165, 170, 190, 210]\n",
    "weights = [40, 60, 65, 80, 92, 130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb373c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.array(heights)\n",
    "y = np.array(weights)\n",
    "points = np.column_stack((x, y))\n",
    "\n",
    "plt.scatter(points[:, 0], points[:, 1], color='blue', label='Random Points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8ba9eb",
   "metadata": {},
   "source": [
    "Now, lets find the best linear model that explains explains the relationship between the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2451c71e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "line_coefficients = np.polyfit(x, y, deg=1)\n",
    "line = np.poly1d(line_coefficients)\n",
    "x_line = np.linspace(x[0], x[-1], 100)\n",
    "y_line = line(x_line)\n",
    "plt.scatter(points[:, 0], points[:, 1], color='blue', label='Random Points')\n",
    "plt.plot(x_line, y_line, color='red', label='Best Fit Line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f363eaf",
   "metadata": {},
   "source": [
    "**Terminology**:\n",
    "- We built a **regression model** to find the relationship between some numerical features\n",
    "- The **predictive features** are also known as **independent variables**, **input variables**, or simply **features**. These are the variables or attributes that are used to make predictions or estimates about the target variable. In this case, the **height**.\n",
    "- The **predictor variable** is the target variable, also known as the **dependent variable** or the **variable being predicted or estimated**. The predictor variable is the variable that we want to model or predict based on the predictive features. In this case, the **height**\n",
    "- **Training data** refers to a labeled dataset that is used to train a machine learning model. It consists of features and predictor variable.\n",
    "\n",
    "Take a look to the parameters learned by the model. Since it is a line, we have the line angle and the constant parameter (also known as the **bias**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7853ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065ea358",
   "metadata": {},
   "source": [
    "**Terminology**: \n",
    "- The **degree of freedom** of a model represents the number of values that are free to vary when fitting the model.\n",
    "- **Model training** or **model fitting** is the process of automatically adjust the model parameters in order to fit the data.\n",
    "- A **loss function**, also known as a **cost function** or **objective function**, is a measure used to quantify the discrepancy or error between the predicted output of a machine learning model and the actual target output.\n",
    "    - Model training adjust the model parameters in order to minimize the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1611b3",
   "metadata": {},
   "source": [
    "There are some differences between the predictions and the model, that may be due to other factors that impact in the person weight. Lets measure the differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f88c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_line_pred = line(x)\n",
    "\n",
    "# Calculate the mean square error for the line and polynomial models\n",
    "mse_line = mean_squared_error(y, y_line_pred)\n",
    "me_line = np.mean(np.abs(y - y_line_pred))\n",
    "me_line, mse_line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef5564a",
   "metadata": {},
   "source": [
    "Now lets test a polynomial model, with more degrees of freadom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a higher-degree polynomial to the points\n",
    "poly_coefficients = np.polyfit(x, y, deg=len(x) - 1)\n",
    "poly = np.poly1d(poly_coefficients)\n",
    "x_poly = np.linspace(x[0], x[-1], 100)\n",
    "y_poly = poly(x_poly)\n",
    "plt.scatter(points[:, 0], points[:, 1], color='blue', label='Random Points')\n",
    "plt.plot(x_poly, y_poly, color='green', label='Exact Fit Polynomial')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9dec42",
   "metadata": {},
   "source": [
    "This model has more degrees of freedom that the line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446750f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poly_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c211c95",
   "metadata": {},
   "source": [
    "lets calculate the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d819eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_poly_pred = poly(x)\n",
    "\n",
    "# Calculate the mean square error for the line and polynomial models\n",
    "mse_line = mean_squared_error(y, y_poly_pred)\n",
    "me_line = np.mean(np.abs(y - y_poly_pred))\n",
    "me_line, mse_line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770ef0b",
   "metadata": {},
   "source": [
    "So, the model was able to fit almost perfectly the training data.\n",
    "- Is this model better than the line?\n",
    "\n",
    "Note that we build models for working on all posible data, not only on training data.\n",
    "- Training data is used as a tool for automaticall inferring the model\n",
    "\n",
    "Lets test both models with some data that was not used in the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89004914",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_other = [140, 160, 180, 201]\n",
    "weights_other = [59, 66, 85, 130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdddd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_test = np.array(heights_other)\n",
    "y_test = np.array(weights_other)\n",
    "plt.plot(x_poly, y_poly, color='green', label='Exact Fit Polynomial')\n",
    "plt.plot(x_line, y_line, color='red', label='Best Fit Line')\n",
    "\n",
    "plt.scatter(points[:, 0], points[:, 1], color='blue', label='Random Points')\n",
    "plt.scatter(x_test, y_test, color='red', label='Random Points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2a5c05",
   "metadata": {},
   "source": [
    "Now, lets repeat the evaluation using the new points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127225f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_line_test = line(x_test)\n",
    "\n",
    "mse_line = mean_squared_error(y_test, y_line_test)\n",
    "me_line = np.mean(np.abs(y_test - y_line_test))\n",
    "print(\"Errors using line:\", (me_line, mse_line))\n",
    "# previous error: (5.502590673575146, 38.894645941278014)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cffd2a",
   "metadata": {},
   "source": [
    "- Errors are larger on testing data, as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14794d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_line_test = poly(x_test)\n",
    "\n",
    "mse_line = mean_squared_error(y_test, y_line_test)\n",
    "me_line = np.mean(np.abs(y_test - y_line_test))\n",
    "print(\"Errors using polygon:\", (me_line, mse_line))\n",
    "# previous error: (1.3872825851043065e-09, 4.46725176381918e-18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633ee9c4",
   "metadata": {},
   "source": [
    "**Note**: On unseen data, errors of the more complex model were significantly larger than errors of the simpler model.\n",
    "\n",
    "**Terminology**: \n",
    "- **Testing data**, also known as **test data** or **validation data**, refers to a subset of labeled data that is used to evaluate the performance of a trained machine learning model. It consists of input data, or features, and their corresponding known output or target values.\n",
    "- **Generalization** refers to the ability of a trained model to perform accurately and make reliable predictions on unseen or new data that it hasn't encountered during the training process. \n",
    "    - It measures how well the model can apply the patterns and relationships learned from the training data to make predictions on previously unseen examples.\n",
    "- **Overtraining**, also known as **overfitting**, refers to a situation in machine learning where a trained model performs extremely well on the training data but fails to generalize well to new, unseen data. \n",
    "    - In other words, the model becomes too specialized in capturing the noise and idiosyncrasies of the training data, leading to poor performance on previously unseen examples.\n",
    "    - Overtraining degrades generalization\n",
    "\n",
    "    \n",
    "    \n",
    "Lets see now other example. We want to estimate the maximum speed that a runner can achieve based on his height. This is training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80138a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = [130, 140, 142, 160, 175, 183, 195, 210, 230]\n",
    "max_speed = [1.1, 1.5, 1.45, 2, 2.9, 3, 2.1, 1.4, 0.9]\n",
    "x = np.array(height)\n",
    "y = np.array(max_speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4cc3d4",
   "metadata": {},
   "source": [
    "Lets plot the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9e50a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df25f134",
   "metadata": {},
   "source": [
    "Now, lets train a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b02a401",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "line_coefficients = np.polyfit(x, y, deg=1)\n",
    "line = np.poly1d(line_coefficients)\n",
    "x_line = np.linspace(x[0], x[-1], 100)\n",
    "y_line = line(x_line)\n",
    "plt.scatter(x, y, color='blue', label='Random Points')\n",
    "plt.plot(x_line, y_line, color='red', label='Best Fit Line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f2243",
   "metadata": {},
   "source": [
    "You can see now that the linear model was unable to capture the information in the training sample. It is because it has too few degrees of freedom to represent the complexity of the problem.\n",
    "\n",
    "Lets try with a polynomial of degree 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32ce93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "line_coefficients = np.polyfit(x, y, deg=4)\n",
    "line = np.poly1d(line_coefficients)\n",
    "x_line = np.linspace(x[0], x[-1], 100)\n",
    "y_line = line(x_line)\n",
    "plt.scatter(x, y, color='blue', label='Random Points')\n",
    "plt.plot(x_line, y_line, color='red', label='Best Fit Line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292c1dfb",
   "metadata": {},
   "source": [
    "Now, our model reflects more accuratelly the relations between the feature and the predictor variable.\n",
    "\n",
    "**Definitions**:\n",
    "- **Undertraining**, also known as **underfitting**, refers to a situation in machine learning where a trained model fails to capture the underlying patterns and relationships present in the training data. \n",
    "    - An undertrained model is unable to sufficiently learn from the data and therefore performs poorly both on the training data and on new, unseen data.\n",
    "    \n",
    "**Note**: Do not forget overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f66d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_coefficients = np.polyfit(x, y, deg=len(x)-1)\n",
    "line = np.poly1d(line_coefficients)\n",
    "x_line = np.linspace(x[0], x[-1], 100)\n",
    "y_line = line(x_line)\n",
    "plt.scatter(x, y, color='blue', label='Random Points')\n",
    "plt.plot(x_line, y_line, color='red', label='Best Fit Line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a87fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_lectures]",
   "language": "python",
   "name": "conda-env-python_lectures-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
