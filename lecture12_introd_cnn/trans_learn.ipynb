{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad09e3f",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d3b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print('GPU', tf.test.gpu_device_name(), 'configured')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04183171",
   "metadata": {},
   "source": [
    "Lets first show the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ce23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def plot_images_in_path(path):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    images = os.listdir(path)\n",
    "    for i, image_name in enumerate(images[:25]):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        imagen = mpimg.imread(os.path.join(path, image_name))\n",
    "        plt.imshow(imagen)\n",
    "    \n",
    "plot_images_in_path('data/face_front_profile/frontal/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d8a50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_images_in_path('data/face_front_profile/profile/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df86d8",
   "metadata": {},
   "source": [
    "Configure the train and testing generator, including data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94051f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation with ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Create the data generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.25,\n",
    "    height_shift_range=0.25,\n",
    "#     shear_range=15,\n",
    "    zoom_range=[0.5, 1.5],\n",
    "    validation_split=0.2  # 30% for testing\n",
    ")\n",
    "\n",
    "# Generators for training and testing sets\n",
    "data_gen_training = datagen.flow_from_directory('data/face_front_profile', target_size=(224, 224),\n",
    "                                                batch_size=32, shuffle=True, subset='training')\n",
    "data_gen_testing = datagen.flow_from_directory('data/face_front_profile', target_size=(224, 224),\n",
    "                                               batch_size=32, shuffle=True, subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6843a",
   "metadata": {},
   "source": [
    "Show examples of augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f295f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 10 images from the training generator\n",
    "for image, label in data_gen_training:\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(image[i])\n",
    "    break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73ac0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b46586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "mobilenetv2 = hub.KerasLayer(url, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0003553a",
   "metadata": {},
   "source": [
    "Now lets freeze the feature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc472cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv2.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a38696",
   "metadata": {},
   "source": [
    "Now add the dense later to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e8775",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    mobilenetv2,\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d1ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f886c8",
   "metadata": {},
   "source": [
    "Now compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e8c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd34d5",
   "metadata": {},
   "source": [
    "Callbacks are useful for many things. Here, we use it for saving models at different epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca384ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=\"frontal_profile_{epoch:02d}.h5\",  # File name with epoch number\n",
    "    save_weights_only=False,  # Save the entire model, not just the weights\n",
    "    period=5  # Save the model every 10 epochs\n",
    ")\n",
    "\n",
    "#Entrenar el modelo\n",
    "EPOCHS = 20\n",
    "\n",
    "# history = model.fit(\n",
    "#     data_gen_training, epochs=EPOCHS, batch_size=32,\n",
    "#     validation_data=data_gen_testing, \n",
    "#     callbacks=[checkpoint_callback]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "trained_model = load_model('frontal_profile_20.h5', custom_objects={'KerasLayer': hub.KerasLayer})\n",
    "trained_model.evaluate(data_gen_testing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_lectures]",
   "language": "python",
   "name": "conda-env-python_lectures-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
