{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e614d5cb",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Presentation (Versioned from StatQuest)\n",
    "\n",
    "## Support vector machines with ScikitLearn\n",
    "\n",
    "Lets use the popular Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222faba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Cargar los datos de la base de datos Iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = iris.target_names\n",
    "\n",
    "# Create a scatter plot for selected features\n",
    "i = 0\n",
    "j = 2\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(X[:, i], X[:, j], c=y, cmap=plt.cm.Set1, edgecolor='k')\n",
    "plt.xlabel(iris.feature_names[i])\n",
    "plt.ylabel(iris.feature_names[j])\n",
    "plt.title(f\"{iris.feature_names[i]} vs {iris.feature_names[j]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12dbbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Create the SVM classifier\n",
    "clf = SVC(kernel='linear')\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae08959",
   "metadata": {},
   "source": [
    "It works better than the decision tree classifier!\n",
    "\n",
    "Now, lets select two features in order to plot the results. I select the features where the classifier gets the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84753dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [0, 2]\n",
    "\n",
    "X_train_2 = X_train[:, selected_features]\n",
    "X_test_2 = X_test[:, selected_features]\n",
    "\n",
    "# Create the SVM classifier\n",
    "clf = SVC(kernel='linear')\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train_2, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_2)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the support vectors and coefficients\n",
    "support_vectors = clf.support_vectors_\n",
    "coef = clf.coef_\n",
    "intercept = clf.intercept_\n",
    "\n",
    "# Plot the support vectors and the separation hyperplane\n",
    "plt.scatter(X_train_2[:, 0], X_train_2[:, 1], c=y_train, cmap=plt.cm.Set1, edgecolor='k')\n",
    "plt.scatter(support_vectors[:, 0], support_vectors[:, 1], facecolors='none', edgecolors='k', linewidths=1.5, s=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b875d40",
   "metadata": {},
   "source": [
    "And now lets plot the decision region for each class, according to the SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac97bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_classification_regions(X, y, clf):\n",
    "    # Plot the separation hyperplane\n",
    "    # Generate a grid of points that span the feature space\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "    # Obtain the predicted labels for each point in the grid\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Reshape the predicted labels into the grid shape\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the contour filled with the predicted labels\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Plot the original data points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "plot_classification_regions(X_train_2, y_train, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d4c1b4",
   "metadata": {},
   "source": [
    "### Type of kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SVM classifier\n",
    "clf = SVC(kernel='rbf')\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SVM classifier\n",
    "clf = SVC(kernel='poly')\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b98fcb7",
   "metadata": {},
   "source": [
    "### The C parameter\n",
    "C: This parameter controls the trade-off between achieving a low training error and a low-margin hyperplane.\n",
    "- A smaller value of C creates a larger margin, potentially allowing more training errors but resulting in a simpler model. \n",
    "- In contrast, a larger value of C leads to a smaller margin and a more complex model that tries to classify all training examples correctly. The default value is C=1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6807dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SVM classifier\n",
    "clf = SVC(kernel='linear', C=20)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_lectures]",
   "language": "python",
   "name": "conda-env-python_lectures-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
