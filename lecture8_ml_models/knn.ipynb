{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3a1204",
   "metadata": {},
   "source": [
    "# The Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48a0a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)  # Select the number of components you want to keep\n",
    "\n",
    "X_train = pd.DataFrame(x_train.reshape((-1, 28*28)))\n",
    "\n",
    "principal_components = pca.fit_transform(X_train)\n",
    "\n",
    "df_train = pd.DataFrame(principal_components, columns=['PC1', 'PC2'])\n",
    "df_train['digit'] = y_train\n",
    "\n",
    "X_test = pd.DataFrame(x_test.reshape((-1, 28*28)))\n",
    "pc_test = pca.transform(X_test)\n",
    "df_test = pd.DataFrame(pc_test, columns=['PC1', 'PC2'])\n",
    "df_test['digit'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddadd0f6",
   "metadata": {},
   "source": [
    "Now we select a sample of the objects belonging to digits 0, 1, and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af9b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.digit.isin({0, 1, 2})].sample(n=100, random_state=23)\n",
    "df_test = df_test[df_test.digit.isin({0, 1, 2})]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c577e5e",
   "metadata": {},
   "source": [
    "And plot the digits in the projected space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d3748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scatter = plt.scatter(df_train['PC1'], df_train['PC2'], c=df_train['digit'], cmap=\"jet\")\n",
    "legend_elements = scatter.legend_elements()\n",
    "labels = [str(digit) for digit in df_train['digit'].unique()]\n",
    "plt.legend(handles=legend_elements[0], labels=labels, title='Digit')\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('PCA Scatter Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99aac65",
   "metadata": {},
   "source": [
    "Now, lets take a point in the test set and plot it together with the training objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606747dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_element(elements):\n",
    "    scatter = plt.scatter(df_train['PC1'], df_train['PC2'], c=df_train['digit'], cmap=\"jet\")\n",
    "    legend_elements = scatter.legend_elements()\n",
    "    labels = [str(digit) for digit in df_test['digit'].unique()]\n",
    "    plt.legend(handles=legend_elements[0], labels=labels, title='Digit')\n",
    "\n",
    "    for element in elements:\n",
    "        plt.scatter(element.PC1, element.PC2, c='red')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.title('PCA Scatter Plot')\n",
    "    plt.show()\n",
    "\n",
    "element = df_test.iloc[0]\n",
    "plot_with_element([element])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e952f730",
   "metadata": {},
   "source": [
    "To which class the red dot belongs?\n",
    "\n",
    "One idea is to assign the object to the class of its closest object in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fed909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "df_train_values = df_train[['PC1', 'PC2']].values\n",
    "\n",
    "def get_nn(obj):\n",
    "    point = np.array([[obj.PC1, obj.PC2]])\n",
    "    distances = cdist(point, df_train_values, metric='euclidean')[0]\n",
    "    idx_min = np.argmin(distances)\n",
    "    return df_train.iloc[idx_min]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2569024f",
   "metadata": {},
   "source": [
    "Now we can compare the digit of some object with the digit of its closest object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5208d9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "element = df_test.iloc[0]\n",
    "print(element)\n",
    "get_nn(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d25c695",
   "metadata": {},
   "source": [
    "So, the class of the closest object, the **nearest neighbor** is the same that the class of the object. Lets see another object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9ea143",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "element = df_test.iloc[1]\n",
    "print(element)\n",
    "get_nn(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f75681d",
   "metadata": {},
   "source": [
    "It is the same! So, it seems that the class of an object is probably the same the the class of its closest object. \n",
    "\n",
    "Lets test in how many object we get the same behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_total, count_correct = 0, 0\n",
    "for idx in range(len(df_test)):\n",
    "    element = df_test.iloc[idx]\n",
    "    nn = get_nn(element)\n",
    "    if nn.digit == element.digit:\n",
    "        count_correct += 1\n",
    "    count_total += 1\n",
    "count_correct / count_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb916df",
   "metadata": {},
   "source": [
    "Since more than 80% of the numbers has a nearest neighbor of its own class, we can use this property to create a classifier: **The nearest neighbor classifier**.\n",
    "\n",
    "As we have seen there are objects where this property does not holds. Lets plot some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_elements = []\n",
    "for idx in range(len(df_test)):\n",
    "    element = df_test.iloc[idx]\n",
    "    nn = get_nn(element)\n",
    "    if nn.digit != element.digit:\n",
    "        wrong_elements.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32030cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_element(wrong_elements[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b5ea6",
   "metadata": {},
   "source": [
    "You can see here that the errors are mainly of two kind:\n",
    "- objects in boundary locations between two classes\n",
    "- objects close to outlayers\n",
    "\n",
    "The nearest neigbor classifier is very sensitive to outliers. \n",
    "- Increase the numbers of neighbors to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def get_k_nn(obj, k):\n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "    knn.fit(df_train_values)\n",
    "    point = np.array([[obj.PC1, obj.PC2]])\n",
    "    distances, indices = knn.kneighbors(point)\n",
    "    nearest_points = df_train.iloc[indices[0]]\n",
    "    return nearest_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e39b4d1",
   "metadata": {},
   "source": [
    "Lets take a look to other neighbors of the incorrectly classified objects we found before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wrong_elements[0])\n",
    "get_k_nn(wrong_elements[0], 7)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94089c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wrong_elements[2])\n",
    "get_k_nn(wrong_elements[2], 7)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fef8f3",
   "metadata": {},
   "source": [
    " If we consider more than one nearest neighbor, we can apply the **majority vote** to select the proper classification.\n",
    " \n",
    " Lets see what happen if we take the closest three neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e67dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "count_total, count_correct = 0, 0\n",
    "for idx in range(len(df_test)):\n",
    "    count_total += 1\n",
    "    element = df_test.iloc[idx]\n",
    "    nn = get_k_nn(element, k)\n",
    "    vote = nn.digit.value_counts().index.tolist()[0]\n",
    "    if vote == element.digit:\n",
    "        count_correct += 1\n",
    "\n",
    "count_correct / count_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ee396",
   "metadata": {},
   "source": [
    "So, it works a little better than with k=1. \n",
    "\n",
    "The nearest neighbors classifier considering more than one neighbor is called K Nearest Neighbor classifier, or KNN.\n",
    "\n",
    "Lets now introduce the scikit-learn code to train the KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1417899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn.fit(df_train[['PC1', 'PC2']], df_train.digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b07fc",
   "metadata": {},
   "source": [
    "Note:\n",
    "- the KNN can be slower while classifying than other classifiers because of the huge amount of distances that need to be calculated for query object\n",
    "- According to the used algorithm, some classifiers have slower training or testing times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f3dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(df_test[['PC1', 'PC2']])\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = accuracy_score(df_test.digit, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ca6e8",
   "metadata": {},
   "source": [
    "Lets explore the influence of k in the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    knn.fit(df_train[['PC1', 'PC2']], df_train.digit)\n",
    "    y_pred = knn.predict(df_test[['PC1', 'PC2']])\n",
    "    accuracy = accuracy_score(df_test.digit, y_pred)\n",
    "    accuracies.append((k, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15048306",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_show = pd.DataFrame(accuracies, columns=['k', 'accuracy'])\n",
    "plt.plot(to_show.k, to_show.accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b62ad1",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- The selection of the value of k have some influence in the quality of the result\n",
    "- To select the best value for k you can use cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9aef13",
   "metadata": {},
   "source": [
    "## The course of dimensionality\n",
    "The \"curse of dimensionality\" refers to the challenges and limitations that arise when working with high-dimensional data. It refers to the phenomenon where the increase in the number of dimensions in a dataset leads to various difficulties in data analysis:\n",
    "- Increase the computational cost of running algorithms\n",
    "- The available data becomes increasingly sparse\n",
    "- Distance values between objects tends to be much more similar to each other\n",
    "\n",
    "Lets see what happen by using 10 features in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_count = 8\n",
    "\n",
    "pca = PCA(n_components=feature_count)  # Select the number of components you want to keep\n",
    "\n",
    "X_train = pd.DataFrame(x_train.reshape((-1, 28*28)))\n",
    "principal_components = pca.fit_transform(X_train)\n",
    "df_train = pd.DataFrame(principal_components, columns=[f'PC{n}' for n in range(feature_count)])\n",
    "df_train['digit'] = y_train\n",
    "X_test = pd.DataFrame(x_test.reshape((-1, 28*28)))\n",
    "pc_test = pca.transform(X_test)\n",
    "df_test = pd.DataFrame(pc_test, columns=[f'PC{n}' for n in range(feature_count)])\n",
    "df_test['digit'] = y_test\n",
    "\n",
    "df_train = df_train[df_train.digit.isin({0, 1, 2})].sample(n=100, random_state=23)\n",
    "df_test = df_test[df_test.digit.isin({0, 1, 2})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a3f7d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    knn.fit(df_train.iloc[:,:-1], df_train.digit)\n",
    "    y_pred = knn.predict(df_test.iloc[:,:-1])\n",
    "    accuracy = accuracy_score(df_test.digit, y_pred)\n",
    "    accuracies.append((k, accuracy))\n",
    "to_show = pd.DataFrame(accuracies, columns=['k', 'accuracy'])\n",
    "plt.plot(to_show.k, to_show.accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a6218",
   "metadata": {},
   "source": [
    "Now, lets increase the number of features to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af0cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "for feature_count in range(2, 110, 10):\n",
    "    pca = PCA(n_components=feature_count)  # Select the number of components you want to keep\n",
    "\n",
    "    X_train = pd.DataFrame(x_train.reshape((-1, 28*28)))\n",
    "    principal_components = pca.fit_transform(X_train)\n",
    "    df_train = pd.DataFrame(principal_components, columns=[f'PC{n}' for n in range(feature_count)])\n",
    "    df_train['digit'] = y_train\n",
    "    X_test = pd.DataFrame(x_test.reshape((-1, 28*28)))\n",
    "    pc_test = pca.transform(X_test)\n",
    "    df_test = pd.DataFrame(pc_test, columns=[f'PC{n}' for n in range(feature_count)])\n",
    "    df_test['digit'] = y_test\n",
    "\n",
    "    df_train = df_train[df_train.digit.isin({0, 1, 2})].sample(n=100, random_state=23)\n",
    "    df_test = df_test[df_test.digit.isin({0, 1, 2})]\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "    knn.fit(df_train.iloc[:,:-1], df_train.digit)\n",
    "    y_pred = knn.predict(df_test.iloc[:,:-1])\n",
    "    accuracy = accuracy_score(df_test.digit, y_pred)\n",
    "    accuracies.append((feature_count, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10909af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_show = pd.DataFrame(accuracies, columns=['feature_count', 'accuracy'])\n",
    "plt.plot(to_show.feature_count, to_show.accuracy)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_lectures]",
   "language": "python",
   "name": "conda-env-python_lectures-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
