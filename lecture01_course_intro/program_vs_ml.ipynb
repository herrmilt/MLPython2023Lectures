{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7c9dd1",
   "metadata": {},
   "source": [
    "# Regular Programming vs Machine Learning\n",
    "\n",
    "In regular programming we process inputs and transform them to obtain outputs. For example, if I want to convert Celsius degrees to Fahrenheit degrees, I can implement the formula:\n",
    "\n",
    "Fahrenheit = Celsius * 1.8 + 32\n",
    "\n",
    "Then, for any value of temperature in Celsius degree, I can obtain Fahrenheit degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db07a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def celsius_to_fahrenheit(v):\n",
    "    return v * 1.8 + 32\n",
    "\n",
    "celsius_to_fahrenheit(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835fcc56",
   "metadata": {},
   "source": [
    "Now, in machine learning we do not know the formula or algorithm or transformation that transforms one value into the other. All we have is examples of inputs and corresponding outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09498a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (-40, -40.0),\n",
    "    (-10, 14.0),\n",
    "    (0, 32.0),\n",
    "    (8, 46.4),\n",
    "    (15, 59.0),\n",
    "    (22, 71.6),\n",
    "    (38, 100.4)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53e67c6",
   "metadata": {},
   "source": [
    "Lets solve this by training a neural network with Tensorflow, a library created by Google for Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdccc29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print('GPU', tf.test.gpu_device_name(), 'configured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ffa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "celsius = np.array([d[0] for d in data], dtype=float)\n",
    "fahrenheit = np.array([d[1] for d in data], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f677f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, input_shape=[1])\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.1),\n",
    "    loss='mean_squared_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21e30d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting training...')\n",
    "history = model.fit(celsius, fahrenheit, epochs=1000, verbose=False)\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028aef5a",
   "metadata": {},
   "source": [
    "Lets take a look to how well is the network doing on each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('# Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd7cbaa",
   "metadata": {},
   "source": [
    "Now, lets make some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce5e8ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = model.predict([100.0])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b548970",
   "metadata": {},
   "outputs": [],
   "source": [
    "celsius_to_fahrenheit(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c69a37f",
   "metadata": {},
   "source": [
    "Lets find the errors with some random celsius values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c89e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "celsius_test = np.random.randint(-30, 150, (12))\n",
    "celsius_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158376c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fahrenheit_test = [celsius_to_fahrenheit(c) for c in celsius_test]\n",
    "print(fahrenheit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31a308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inferred_fahrenheit = model.predict(celsius_test)\n",
    "print(inferred_fahrenheit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486c391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_square_error = sum((real-inferr)**2 for real, inferr in zip(fahrenheit_test, inferred_fahrenheit))\n",
    "mean_square_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc484a",
   "metadata": {},
   "source": [
    "Lets see what the network learned so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a282a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1002b27f",
   "metadata": {},
   "source": [
    "Compare it with the actual equation:\n",
    "\n",
    "Fahrenheit = Celsius * 1.8 + 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6455edd",
   "metadata": {},
   "source": [
    "In conclusion, we manage to build a **model** that correctly maps between Celsius degrees to Fahrenheit degrees based only in examples.\n",
    "\n",
    "**This machine learning task is knows as Regression and we use a Neural Network Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5383e790",
   "metadata": {},
   "source": [
    "Lets see another example with a different task. We have some rules that allow us to classify the type of an animal based on some characteristics:\n",
    "\n",
    "- Weight > 100 kg:\n",
    "    - Yes: Hair?\n",
    "        - Yes: Bear\n",
    "        - No: Leave on water?\n",
    "            - Yes: Whale\n",
    "            - No: Anaconda\n",
    "    - No: Fly?\n",
    "        - Yes: Eagle\n",
    "        - No: Cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad283c02",
   "metadata": {},
   "source": [
    "This is Biology, so if I have some animal description, I can automatically find which animal it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_animal(weight, hair, water, fly):\n",
    "    if weight > 100:\n",
    "        if hair:\n",
    "            return \"Bear\"\n",
    "        else:\n",
    "            if water:\n",
    "                return \"Whale\"\n",
    "            else:\n",
    "                return \"Anaconda\"\n",
    "    else:\n",
    "        if fly:\n",
    "            return \"Eagle\"\n",
    "        else:\n",
    "            return \"Cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259cda9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_animal(120, True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f69db",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_animal(5, True, False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f3752",
   "metadata": {},
   "source": [
    "The machile learning problem appears when I have some animal descriptions together with the current type of animal, and I want to create a model that, based on the descriptions, can infer the type of animal.\n",
    "\n",
    "First, generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce345eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_animals(n):    \n",
    "    result = []\n",
    "    for _ in range(n):\n",
    "        weight = random.randint(1, 200)\n",
    "        hair = random.random() > 0.5\n",
    "        water = random.random() > 0.5\n",
    "        fly = random.random() > 0.5\n",
    "        animal = get_animal(weight, hair, water, fly)\n",
    "        result.append((weight, hair, water, fly, animal))\n",
    "    return result    \n",
    "        \n",
    "for weight, hair, water, fly, animal in generate_random_animals(5):\n",
    "    print(weight, hair, water, fly, \"** Animal:\",  animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_random_animals(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd52d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e101213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['weight', 'hair', 'water', 'fly', 'animal'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['weight', 'hair', 'water', 'fly']\n",
    "X = df[feature_cols] # Features\n",
    "y = df.animal # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92668afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823f8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(r, p) for r, p in zip(y_test, y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c5a97",
   "metadata": {},
   "source": [
    "Lets take a look to the model built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5531da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "text_representation = tree.export_text(clf, feature_names=['weight', 'hair', 'water', 'fly'])\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047de2de",
   "metadata": {},
   "source": [
    "**This machine learning task is known as suppervised classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f82c92",
   "metadata": {},
   "source": [
    "Lets see another example. Here we are trying to estimate the correct number from its handwritten image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61d5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf997db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7d1919",
   "metadata": {},
   "source": [
    "Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd983a5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Calculate the number of rows and columns for the grid\n",
    "n_rows = 4\n",
    "n_cols = 4\n",
    "\n",
    "# Create a new figure with the desired grid size\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5, 5))\n",
    "\n",
    "# Iterate over the image files and display them in the grid\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(x_train[i], cmap=\"gray\")\n",
    "    ax.set_title(f\"Number:{y[i]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "# Adjust the spacing and layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7affad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and normalize the input data\n",
    "x_train = x_train.reshape(-1, 784) / 255.0\n",
    "x_test = x_test.reshape(-1, 784) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2c3a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(784,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee02d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee38208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('# Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b0ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b97d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save('data/get_digit_ann.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d3c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image, ImageDraw\n",
    "import PIL\n",
    "from tkinter import *\n",
    "\n",
    "width = 200  # canvas width\n",
    "height = 200 # canvas height\n",
    "center = height//2\n",
    "white = (255, 255, 255) # canvas back\n",
    "\n",
    "def paint(event):\n",
    "    x1, y1 = (event.x - 1), (event.y - 1)\n",
    "    x2, y2 = (event.x + 1), (event.y + 1)\n",
    "    canvas.create_oval(x1, y1, x2, y2, fill=\"black\",width=10)\n",
    "    draw.line([x1, y1, x2, y2],fill=\"black\",width=10)\n",
    "   \n",
    "master = Tk()\n",
    "\n",
    "def close_window():\n",
    "    master.destroy()\n",
    "\n",
    "# create a tkinter canvas to draw on\n",
    "canvas = Canvas(master, width=width, height=height, bg='white')\n",
    "canvas.pack()\n",
    "\n",
    "# create an empty PIL image and draw object to draw on\n",
    "output_image = PIL.Image.new(\"RGB\", (width, height), white)\n",
    "draw = ImageDraw.Draw(output_image)\n",
    "canvas.pack(expand=YES, fill=BOTH)\n",
    "canvas.bind(\"<B1-Motion>\", paint)\n",
    "\n",
    "button=Button(text=\"close\",command=close_window)\n",
    "button.pack()\n",
    "\n",
    "master.mainloop()\n",
    "\n",
    "resized_image = output_image.resize((28, 28))\n",
    "\n",
    "# Convert the image to grayscale\n",
    "grayscale_image = resized_image.convert(\"L\")\n",
    "\n",
    "# Convert the image to a NumPy array\n",
    "image_array = np.array(grayscale_image)\n",
    "\n",
    "normalized_image = 1 - image_array / 255.0\n",
    "reshaped_image = np.reshape(normalized_image, (1, 28*28))\n",
    "reshaped_image = reshaped_image.astype(np.float32)\n",
    "predictions = model.predict(reshaped_image)\n",
    "\n",
    "# Get the predicted class index\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "\n",
    "# Print the predicted class index\n",
    "print(\"Predicted class index:\", predicted_class_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e75774f",
   "metadata": {},
   "source": [
    "You can see that if the numbers are written in a location similar to the training set, the network is performing a good job.\n",
    "- If you move the numbers, the inputs are quite different to the original numbers, and the output is sort of random\n",
    "- For something better, we will introduce later the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b166d62",
   "metadata": {},
   "source": [
    "**This task is also a suppervised classification, but using images as inputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3368eea7",
   "metadata": {},
   "source": [
    "Lets see a final example. The manager of a chain of stores wants to understand the behavior of their customers in order to direct advertising campaigns to similar subsets of customers.\n",
    "\n",
    "The available data includes: gender, age, annual income, and a score between 0 and 100 that evaluates the magnitude of purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3a9ac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Mall_Customers.csv\", index_col='CustomerID')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43caae8d",
   "metadata": {},
   "source": [
    "First, we simplify the name of some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf78290",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.rename(index=str, columns={'Annual Income (k$)': 'Income',\n",
    "                              'Spending Score (1-100)': 'Score'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5abad3",
   "metadata": {},
   "source": [
    "Now, we will try to understand data using pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b180b32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "sn.pairplot(df, hue='Gender', aspect=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f070651a",
   "metadata": {},
   "source": [
    "We conclude that gender is not important and can be removed from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Gender'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c123f9",
   "metadata": {},
   "source": [
    "We will use the KMeans clustering algorithm, which decomposes the dataframe into groups of objects that are very similar to each other and dissimilar to the objects in other groups. As a result, we also obtain a representative object for each group, which is the object most similar to the others.\n",
    "\n",
    "This algorithm takes the number of desired groups (k) as a parameter. Lets try with k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6401df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km3 = KMeans(n_clusters=3, n_init=\"auto\", random_state=314).fit(X)\n",
    "\n",
    "X['Labels'] = km3.labels_\n",
    "plt.figure(figsize=(12, 8))\n",
    "sn.scatterplot(x=X['Income'], y=X['Score'], hue=X['Labels'], \n",
    "                palette=sn.color_palette('hls', 3))\n",
    "plt.title('KMeans with 3 Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1697a7aa",
   "metadata": {},
   "source": [
    "Lets test what happen with k values from  2 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39cdd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "\n",
    "for i in range(2, 11):\n",
    "    km = KMeans(n_clusters=i, n_init=\"auto\", random_state=314).fit(X)\n",
    "    clusters.append(km.inertia_)\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sn.lineplot(x=list(range(2, 11)), y=clusters, ax=ax)\n",
    "ax.set_title('Searching for Elbow')\n",
    "ax.set_xlabel('Clusters')\n",
    "ax.set_ylabel('Inertia')\n",
    "\n",
    "# Annotate arrow\n",
    "ax.annotate('Possible Elbow Point', xy=(3, 140000), xytext=(3, 50000), xycoords='data',          \n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))\n",
    "\n",
    "ax.annotate('Possible Elbow Point', xy=(5, 80000), xytext=(5, 150000), xycoords='data',          \n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e20f6",
   "metadata": {},
   "source": [
    "So, lets test with k = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ace06",
   "metadata": {},
   "outputs": [],
   "source": [
    "km5 = KMeans(n_clusters=5, n_init=\"auto\", random_state=314).fit(X)\n",
    "\n",
    "X['Labels'] = km5.labels_\n",
    "plt.figure(figsize=(12, 8))\n",
    "sn.scatterplot(x=X['Income'], y=X['Score'], hue=X['Labels'], \n",
    "                palette=sn.color_palette('hls', 5))\n",
    "plt.title('KMeans with 3 Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da48346",
   "metadata": {},
   "source": [
    "The results with k=5 are better that with k=3. \n",
    "\n",
    "**Note** the highly subjective nature of this evaluation, as unlike previous examples, here we do not have prior knowledge to perform an objective evaluation.\n",
    "\n",
    "The 5 obtained clusters can be explained as follows:\n",
    "\n",
    "    Label 0: high income and low expenses\n",
    "    Label 1: low income and expenses\n",
    "    Label 2: high income and expenses\n",
    "    Label 3: average income and expenses\n",
    "    Label 4: low income and high expenses\n",
    "\n",
    "In conclusion, the client can notice that there is a segment with high income and low expenses, to which they could direct a more aggressive advertising strategy and potentially achieve good results.\n",
    "\n",
    "Another conclusion is that there is a segment that spends more than their income, which is interesting to consider.\n",
    "\n",
    "**This type of machine learning task is known as clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb1d25",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- In regular programming, we provide the algorithm or formula to transform the inputs in outputs\n",
    "- In machine learning, we prodide examples of inputs and its corresponding outputs, and make the algorithms to figure out a good model for doing the transformation\n",
    "    - There are different models for performing each task\n",
    "    - Every model has different parameters that impacts the quality of the results\n",
    "    - Selecting the best option is a combination of experience and a trial-and-error strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1abb4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_lectures]",
   "language": "python",
   "name": "conda-env-python_lectures-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
